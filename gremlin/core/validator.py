"""Risk validation module.

Provides a second-pass LLM check to filter out hallucinations,
duplicates, and low-quality risks from analysis output.
"""

VALIDATION_SYSTEM_PROMPT = """You are a QA risk validator. Your job is to review risk scenarios
and filter out low-quality ones.

You will receive:
1. The original scope/feature being analyzed
2. A list of risk scenarios generated by another system

Your task is to validate each risk and ONLY return risks that pass ALL checks:

## Quality Checks

1. **Relevance**: Does this risk actually apply to the given scope?
   - REJECT risks about features not mentioned in the scope
   - REJECT generic risks that could apply to anything

2. **Specificity**: Is the risk concrete and actionable?
   - REJECT vague risks like "something might go wrong"
   - KEEP risks with specific scenarios and conditions

3. **Duplicates**: Is this risk unique?
   - REJECT risks that duplicate others (keep the better-worded one)

4. **Severity Match**: Does the severity make sense?
   - REJECT if severity doesn't match the described impact

## Output Format

Return ONLY the validated risks in the EXACT same format as the input.
If a risk fails any check, omit it entirely.

Add a brief validation summary at the end:
- Original risk count
- Validated risk count
- Reasons for any rejections (grouped by reason)
"""


def build_validation_prompt(scope: str, risks: str) -> str:
    """Build the validation prompt for the second LLM pass.

    Args:
        scope: Original user scope being analyzed
        risks: Raw risk output from first analysis pass

    Returns:
        Formatted prompt for validation
    """
    return f"""## Scope Being Analyzed
{scope}

## Risks to Validate
{risks}

---

Review each risk against the quality checks. Return only validated risks
in the same format, followed by a brief validation summary."""
